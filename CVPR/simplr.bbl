\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bao et~al.(2022)Bao, Dong, Piao, and Wei]{bao2022beit}
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In \emph{ICLR}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Amanda~Askell, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{brown2020gpt3}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Sandhini~Agarwal Amanda~Askell, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and Zagoruyko]{nicolas2020detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{ECCV}, 2020.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Radford, Child, Wu, Jun, Dhariwal, Luan, and Sutskever]{chen2020igpt}
Mark Chen, Alec Radford, Rewon Child, Jeff Wu, Heewoo Jun, Prafulla Dhariwal, David Luan, and Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and Hinton]{chen2020simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{ICML}, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2022)Chen, Du, Yang, Beyer, Zhai, Lin, Chen, Li, Song, Wang, and Zhou]{chen2022uvit}
Wuyang Chen, Xianzhi Du, Fan Yang, Lucas Beyer, Xiaohua Zhai, Tsung-Yi Lin, Huizhong Chen, Jing Li, Xiaodan Song, Zhangyang Wang, and Denny Zhou.
\newblock A simple single-scale vision transformer for object localization and instance segmentation.
\newblock In \emph{ECCV}, 2022.

\bibitem[Cheng et~al.(2021)Cheng, Schwing, and Kirillov]{cheng2021maskformer}
Bowen Cheng, Alexander~G. Schwing, and Alexander Kirillov.
\newblock Per-pixel classification is not all you need for semantic segmentation.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Cheng et~al.(2022)Cheng, Misra, Schwing, Kirillov, and Girdhar]{cheng2022mask2former}
Bowen Cheng, Ishan Misra, Alexander~G. Schwing, Alexander Kirillov, and Rohit Girdhar.
\newblock Mask2former: Masked-attention mask transformer for universal image segmentation.
\newblock In \emph{CVPR}, 2022.

\bibitem[Dehghani et~al.(2023)Dehghani, Djolonga, Mustafa, and et~al.]{dehghani2023scalingvit22b}
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, and et al.
\newblock Scaling vision transformers to 22 billion parameters.
\newblock In \emph{ICML}, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock In \emph{ACL}, 2019.

\bibitem[Dong et~al.(2021)Dong, Zeng, Wang, Zhang, and Wei]{dong2021solq}
Bin Dong, Fangao Zeng, Tiancai Wang, Xiangyu Zhang, and Yichen Wei.
\newblock {SOLQ}: Segmenting objects by learning queries.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{dosovitskiy2021vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{ICLR}, 2021.

\bibitem[Fan et~al.(2021)Fan, Xiong, Mangalam, Li, Yan, Malik, and Feichtenhofer]{fan2021mvit}
Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock In \emph{ICCV}, 2021.

\bibitem[Ghiasi et~al.(2021)Ghiasi, Cui, Srinivas, Qian, Lin, Cubuk, Le, and Zoph]{shiasi2021lsjitter}
Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, TsungYi Lin, Ekin~D Cubuk, Quoc~V Le, and Barret Zoph.
\newblock Simple copy-paste is a strong data augmentation method for instance segmentation.
\newblock In \emph{CVPR}, 2021.

\bibitem[Girshick et~al.(2014)Girshick, Donahue, Darrell, and Malik]{girshick2014rcnn}
Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
\newblock Rich feature hierarchies for accurate object detection and semantic segmentation.
\newblock In \emph{CVPR}, 2014.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{kaiming2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[He et~al.(2017)He, Gkioxari, Doll치r, and Girshick]{he2017maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll치r, and Ross Girshick.
\newblock Mask {R-CNN}.
\newblock In \emph{ICCV}, 2017.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{CVPR}, 2022.

\bibitem[Heo et~al.(2021)Heo, Yun, Han, Chun, Choe, and Oh]{heo2021rethinkingvit}
Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe, and Seong~Joon Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock In \emph{ICCV}, 2021.

\bibitem[Huang et~al.(2017)Huang, Liu, van~der Maaten, and Weinberger]{huang2017densenet}
Gao Huang, Zhuang Liu, Laurens van~der Maaten, and Kilian~Q. Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{CVPR}, 2017.

\bibitem[Jia et~al.(2023)Jia, Yuan, He, Wu, Yu, Lin, Sun, Zhang, and Hu]{jia2023hybridmatching}
Ding Jia, Yuhui Yuan, Haodi He, Xiaopei Wu, Haojun Yu, Weihong Lin, Lei Sun, Chao Zhang, and Han Hu.
\newblock Detrs with hybrid matching.
\newblock In \emph{CVPR}, 2023.

\bibitem[Kirillov et~al.(2019)Kirillov, He, Girshick, Rother, and Dollar]{kirillov2019panoptic}
Alexander Kirillov, Kaiming He, Ross Girshick, Carsten Rother, and Piotr Dollar.
\newblock Panoptic segmentation.
\newblock In \emph{CVPR}, 2019.

\bibitem[LeCun and Bengio(1995)]{lecun95convolutional}
Yann LeCun and Yoshua Bengio.
\newblock \emph{Convolutional Networks for Images, Speech and Time Series}, pages 255--258.
\newblock MIT Press, 1995.

\bibitem[Li et~al.(2023)Li, Zhang, xu, Liu, Zhang, Ni, and Shum]{li2023maskdino}
Feng Li, Hao Zhang, Huaizhe xu, Shilong Liu, Lei Zhang, Lionel~M. Ni, and Heung-Yeung Shum.
\newblock Mask dino: Towards a unified transformer-based framework for object detection and segmentation.
\newblock In \emph{CVPR}, 2023.

\bibitem[Li et~al.(2022)Li, Mao, Girshick, and He]{li2022vitdet}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock In \emph{ECCV}, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Bourdev, Girshick, Hays, Perona, Ramanan, Doll{\'{a}}r, and Zitnick]{lin2014mscoco}
Tsung{-}Yi Lin, Michael Maire, Serge~J. Belongie, Lubomir~D. Bourdev, Ross~B. Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'{a}}r, and C.~Lawrence Zitnick.
\newblock Microsoft {COCO:} common objects in context.
\newblock In \emph{ECCV}, 2014.

\bibitem[{Lin} et~al.(2017){Lin}, {Doll치r}, {Girshick}, {He}, {Hariharan}, and {Belongie}]{tsung2017fpn}
Tsung-Yi {Lin}, Piotr {Doll치r}, Ross {Girshick}, Kaiming {He}, Bharath {Hariharan}, and Serge {Belongie}.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{CVPR}, 2017.

\bibitem[Lin et~al.(2023)Lin, Yuan, Zhang, Li, Zheng, and Hu]{lin2023plaindetr}
Yutong Lin, Yuhui Yuan, Zheng Zhang, Chen Li, Nanning Zheng, and Han Hu.
\newblock {DETR} does not need multi-scale or locality design.
\newblock In \emph{ICCV}, 2023.

\bibitem[Liu et~al.(2016)Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg]{wei2016ssd}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander~C. Berg.
\newblock {SSD}: Single shot multibox detector.
\newblock In \emph{ECCV}, 2016.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swintransformer}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{ICCV}, 2021.

\bibitem[Loshchilov and Hutter(2019)]{loshchilov2019adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In \emph{ICLR}, 2019.

\bibitem[Nguyen et~al.(2022)Nguyen, Ju, Booij, Oswald, and Snoek]{nguyen2022boxer}
Duy{-}Kien Nguyen, Jihong Ju, Olaf Booij, Martin~R. Oswald, and Cees G.~M. Snoek.
\newblock Boxer: Box-attention for 2d and 3d transformers.
\newblock In \emph{CVPR}, 2022.

\bibitem[Peng et~al.(2022)Peng, Dong, Bao, Ye, and Wei]{peng2022beitv2}
Zhiliang Peng, Li Dong, Hangbo Bao, Qixiang Ye, and Furu Wei.
\newblock {BEiT v2}: Masked image modeling with vector-quantized visual tokenizers.
\newblock \emph{arXiv preprint arXiv:2208.06366}, 2022.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015faster_rcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster {R-CNN}: Towards real-time object detection with region proposal networks.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Simonyan and Zisserman(2015)]{simonyan2015vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{ICLR}, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Zhu, Adam, Yuille, and Chen]{wang2021maxdeeplab}
Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen.
\newblock Max-deeplab: End-to-end panoptic segmentation with mask transformers.
\newblock In \emph{CVPR}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and Shao]{wang2021pvit}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction without convolutions.
\newblock In \emph{ICCV}, 2021{\natexlab{b}}.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'{a}}r, Tu, and He]{xie2017resnext}
Saining Xie, Ross~B. Girshick, Piotr Doll{\'{a}}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{CVPR}, 2017.

\bibitem[Yu et~al.(2022)Yu, Wang, Qiao, Collins, Zhu, Adam, Yuille, and Chen]{yu2022kmmask}
Qihang Yu, Huiyu Wang, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen.
\newblock k-means mask transformer.
\newblock In \emph{ECCV}, 2022.

\bibitem[Zhai et~al.(2022)Zhai, Kolesnikov, Houlsby, and Beyer]{zhai2022scalingvit}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In \emph{CVPR}, 2022.

\bibitem[Zhang et~al.(2023)Zhang, Li, Liu, Zhang, Su, Zhu, Ni, and Shum]{zhang2023dino}
Hao Zhang, Feng Li, Shilong Liu, Lei Zhang, Hang Su, Jun Zhu, Lionel Ni, and Heung-Yeung Shum.
\newblock Dino: Detr with improved denoising anchor boxes for end-to-end object detection.
\newblock In \emph{ICLR}, 2023.

\bibitem[Zhang et~al.(2021)Zhang, Pang, Chen, and Loy]{zhang2021knet}
Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen~Change Loy.
\newblock K-net: Towards unified image segmentation.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Zhu et~al.(2021)Zhu, Su, Lu, Li, Wang, and Dai]{zhu2021deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable {DETR}: Deformable transformers for end-to-end object detection.
\newblock In \emph{ICLR}, 2021.

\end{thebibliography}
