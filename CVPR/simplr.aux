\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{he2022mae}
\citation{li2022vitdet}
\citation{nguyen2022boxer}
\citation{lin2023plaindetr}
\citation{he2022mae}
\citation{li2022vitdet}
\citation{nguyen2022boxer}
\citation{lin2023plaindetr}
\citation{vaswani2017transformer}
\citation{liu2021swintransformer,dosovitskiy2021vit}
\citation{nicolas2020detr,zhu2021deformable,nguyen2022boxer}
\citation{wang2021maxdeeplab,zhang2021knet,cheng2022mask2former}
\citation{brown2020gpt3,devlin2019bert}
\citation{liu2021swintransformer}
\citation{fan2021mvit,wang2021pvit,heo2021rethinkingvit}
\citation{tsung2017fpn}
\citation{li2022vitdet}
\citation{dosovitskiy2021vit}
\citation{he2022mae,bao2022beit,dehghani2023scalingvit22b}
\citation{nicolas2020detr}
\@LN@col{1}
\@LN{0}{0}
\@LN{1}{0}
\@LN{2}{0}
\@LN{3}{0}
\@LN{4}{0}
\@LN{5}{0}
\@LN{6}{0}
\@LN{7}{0}
\@LN{8}{0}
\@LN{9}{0}
\@LN{10}{0}
\@LN{11}{0}
\@LN{12}{0}
\@LN{13}{0}
\@LN{14}{0}
\@LN{15}{0}
\@LN{16}{0}
\@LN{17}{0}
\@LN{18}{0}
\@LN{19}{0}
\@LN{20}{0}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{\hskip -1em.~Introduction}{section.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][]1}{[1][1][]1}}
\@LN{21}{0}
\@writefile{brf}{\backcite{vaswani2017transformer}{{1}{1}{figure.caption.1}}}
\@LN{22}{0}
\@LN{23}{0}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{liu2021swintransformer}{{1}{1}{figure.caption.1}}}
\@LN{24}{0}
\@writefile{brf}{\backcite{nicolas2020detr}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{wang2021maxdeeplab}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{zhang2021knet}{{1}{1}{figure.caption.1}}}
\@LN{25}{0}
\@LN{26}{0}
\@LN{27}{0}
\@writefile{brf}{\backcite{brown2020gpt3}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{devlin2019bert}{{1}{1}{figure.caption.1}}}
\@LN{28}{0}
\@LN{29}{0}
\@LN{30}{0}
\@LN{31}{0}
\@LN{32}{0}
\@LN{33}{0}
\@LN{34}{0}
\@LN{35}{0}
\@LN{36}{0}
\@LN@col{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  \textbf  {A plain detector is non-trivial.} Even with the use of a plain backbone ViT pre-trained using MAE\nobreakspace  {}\cite  {he2022mae}, feature pyramids are still important for both convolution-based (ViTDet\nobreakspace  {}\cite  {li2022vitdet}) and transformer-based (BoxeR\nobreakspace  {}\cite  {nguyen2022boxer}) detectors. While removing multi-scale input from the encoder, PlainDETR\nobreakspace  {}\cite  {lin2023plaindetr} still relies on feature pyramids for its box proposal generation and lags behind in performance. In this paper, we demonstrate that the plain detector, SimPLR\xspace  , with the proposed scale-aware attention yields competitive performance compared to multi-scale counterparts. \relax }}{1}{figure.caption.1}\protected@file@percent }
\@writefile{brf}{\backcite{he2022mae}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{li2022vitdet}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{lin2023plaindetr}{{1}{1}{figure.caption.1}}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:single_scale}{{1}{1}{\textbf {A plain detector is non-trivial.} Even with the use of a plain backbone ViT pre-trained using MAE~\cite {he2022mae}, feature pyramids are still important for both convolution-based (ViTDet~\cite {li2022vitdet}) and transformer-based (BoxeR~\cite {nguyen2022boxer}) detectors. While removing multi-scale input from the encoder, PlainDETR~\cite {lin2023plaindetr} still relies on feature pyramids for its box proposal generation and lags behind in performance. In this paper, we demonstrate that the plain detector, \ours , with the proposed scale-aware attention yields competitive performance compared to multi-scale counterparts. \relax }{figure.caption.1}{}}
\newlabel{fig:single_scale@cref}{{[figure][1][]1}{[1][1][]1}}
\@LN{37}{0}
\@LN{38}{0}
\@LN{39}{0}
\@LN{40}{0}
\@LN{41}{0}
\@LN{42}{0}
\@LN{43}{0}
\@LN{44}{0}
\@writefile{brf}{\backcite{liu2021swintransformer}{{1}{1}{figure.caption.1}}}
\@LN{45}{0}
\@writefile{brf}{\backcite{fan2021mvit}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{heo2021rethinkingvit}{{1}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{wang2021pvit}{{1}{1}{figure.caption.1}}}
\@LN{46}{0}
\@LN{47}{0}
\@LN{48}{0}
\@LN{49}{0}
\@writefile{brf}{\backcite{tsung2017fpn}{{1}{1}{figure.caption.1}}}
\@LN{50}{0}
\@LN{51}{0}
\@LN{52}{0}
\@writefile{brf}{\backcite{li2022vitdet}{{1}{1}{figure.caption.1}}}
\@LN{53}{0}
\@LN{54}{0}
\@LN{55}{0}
\citation{dosovitskiy2021vit,li2022vitdet}
\citation{ren2015faster_rcnn,he2017maskrcnn,li2022vitdet}
\citation{zhu2021deformable,nguyen2022boxer,cheng2022mask2former}
\citation{nicolas2020detr,zhu2021deformable,nguyen2022boxer,cheng2022mask2former}
\citation{li2022vitdet}
\citation{cheng2022mask2former}
\citation{he2022mae}
\citation{peng2022beitv2}
\citation{girshick2014rcnn}
\citation{simonyan2015vgg,xie2017resnext,kaiming2016resnet,huang2017densenet}
\citation{lecun95convolutional}
\citation{deng2009imagenet}
\citation{brown2020gpt3,devlin2019bert}
\citation{chen2020igpt,dosovitskiy2021vit,liu2021swintransformer}
\citation{dosovitskiy2021vit}
\citation{chen2020simclr,he2022mae}
\citation{nicolas2020detr}
\citation{dong2021solq,wang2021maxdeeplab,nguyen2022boxer}
\citation{cheng2021maskformer}
\citation{zhang2021knet}
\citation{cheng2022mask2former}
\citation{yu2022kmmask}
\citation{zhang2023dino,li2023maskdino}
\citation{chen2022uvit}
\citation{li2022vitdet}
\citation{he2022mae}
\@LN@col{1}
\@LN{56}{1}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{2}{1}{figure.caption.1}}}
\@LN{57}{1}
\@LN{58}{1}
\@LN{59}{1}
\@LN{60}{1}
\@writefile{brf}{\backcite{bao2022beit}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{dehghani2023scalingvit22b}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{he2022mae}{{2}{1}{figure.caption.1}}}
\@LN{61}{1}
\@writefile{brf}{\backcite{nicolas2020detr}{{2}{1}{figure.caption.1}}}
\@LN{62}{1}
\@LN{63}{1}
\@LN{64}{1}
\@LN{65}{1}
\@LN{66}{1}
\@LN{67}{1}
\@LN{68}{1}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{li2022vitdet}{{2}{1}{figure.caption.1}}}
\@LN{69}{1}
\@LN{70}{1}
\@LN{71}{1}
\@LN{72}{1}
\@LN{73}{1}
\@writefile{brf}{\backcite{he2017maskrcnn}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{li2022vitdet}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{ren2015faster_rcnn}{{2}{1}{figure.caption.1}}}
\@LN{74}{1}
\@writefile{brf}{\backcite{cheng2022mask2former}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{2}{1}{figure.caption.1}}}
\@LN{75}{1}
\@LN{76}{1}
\@LN{77}{1}
\@LN{78}{1}
\@LN{79}{1}
\@LN{80}{1}
\@LN{81}{1}
\@LN{82}{1}
\@writefile{brf}{\backcite{nicolas2020detr}{{2}{1}{figure.caption.1}}}
\@LN{83}{1}
\@writefile{brf}{\backcite{cheng2022mask2former}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{2}{1}{figure.caption.1}}}
\@LN{84}{1}
\@LN{85}{1}
\@LN{86}{1}
\@LN{87}{1}
\@LN{88}{1}
\@LN{89}{1}
\@LN{90}{1}
\@LN{91}{1}
\@LN{92}{1}
\@LN{93}{1}
\@LN{94}{1}
\@LN{95}{1}
\@LN{96}{1}
\@LN{97}{1}
\@LN{98}{1}
\@LN{99}{1}
\@LN{100}{1}
\@LN{101}{1}
\@writefile{brf}{\backcite{li2022vitdet}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{2}{1}{figure.caption.1}}}
\@LN{102}{1}
\@LN{103}{1}
\@LN{104}{1}
\@LN{105}{1}
\@LN{106}{1}
\@LN{107}{1}
\@writefile{brf}{\backcite{he2022mae}{{2}{1}{figure.caption.1}}}
\@writefile{brf}{\backcite{peng2022beitv2}{{2}{1}{figure.caption.1}}}
\@LN{108}{1}
\@LN@col{2}
\@LN{109}{1}
\@LN{110}{1}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_work}{{2}{2}{\hskip -1em.~Related Work}{section.2}{}}
\newlabel{sec:related_work@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{brf}{\backcite{girshick2014rcnn}{{2}{2}{section.2}}}
\@LN{111}{1}
\@LN{112}{1}
\@LN{113}{1}
\@writefile{brf}{\backcite{kaiming2016resnet}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{huang2017densenet}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{simonyan2015vgg}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{xie2017resnext}{{2}{2}{section.2}}}
\@LN{114}{1}
\@writefile{brf}{\backcite{lecun95convolutional}{{2}{2}{section.2}}}
\@LN{115}{1}
\@writefile{brf}{\backcite{deng2009imagenet}{{2}{2}{section.2}}}
\@LN{116}{1}
\@writefile{brf}{\backcite{brown2020gpt3}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{devlin2019bert}{{2}{2}{section.2}}}
\@LN{117}{1}
\@writefile{brf}{\backcite{chen2020igpt}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{liu2021swintransformer}{{2}{2}{section.2}}}
\@LN{118}{1}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{2}{2}{section.2}}}
\@LN{119}{1}
\@LN{120}{1}
\@LN{121}{1}
\@LN{122}{1}
\@LN{123}{1}
\@writefile{brf}{\backcite{chen2020simclr}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{he2022mae}{{2}{2}{section.2}}}
\@LN{124}{1}
\@LN{125}{1}
\@LN{126}{1}
\@LN{127}{1}
\@writefile{brf}{\backcite{nicolas2020detr}{{2}{2}{section.2}}}
\@LN{128}{1}
\@LN{129}{1}
\@LN{130}{1}
\@writefile{brf}{\backcite{dong2021solq}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{wang2021maxdeeplab}{{2}{2}{section.2}}}
\@LN{131}{1}
\@LN{132}{1}
\@LN{133}{1}
\@writefile{brf}{\backcite{cheng2021maskformer}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{zhang2021knet}{{2}{2}{section.2}}}
\@LN{134}{1}
\@LN{135}{1}
\@LN{136}{1}
\@writefile{brf}{\backcite{cheng2022mask2former}{{2}{2}{section.2}}}
\@LN{137}{1}
\@LN{138}{1}
\@writefile{brf}{\backcite{yu2022kmmask}{{2}{2}{section.2}}}
\@LN{139}{1}
\@LN{140}{1}
\@LN{141}{1}
\@writefile{brf}{\backcite{li2023maskdino}{{2}{2}{section.2}}}
\@writefile{brf}{\backcite{zhang2023dino}{{2}{2}{section.2}}}
\@LN{142}{1}
\@LN{143}{1}
\@LN{144}{1}
\@LN{145}{1}
\@LN{146}{1}
\@LN{147}{1}
\@LN{148}{1}
\@LN{149}{1}
\@LN{150}{1}
\@LN{151}{1}
\@LN{152}{1}
\@LN{153}{1}
\@writefile{brf}{\backcite{chen2022uvit}{{2}{2}{section.2}}}
\@LN{154}{1}
\@LN{155}{1}
\@LN{156}{1}
\@LN{157}{1}
\@LN{158}{1}
\@writefile{brf}{\backcite{li2022vitdet}{{2}{2}{section.2}}}
\@LN{159}{1}
\@LN{160}{1}
\citation{lin2023plaindetr}
\citation{jia2023hybridmatching}
\citation{zhu2021deformable,nguyen2022boxer}
\citation{zhu2021deformable,li2022vitdet,nguyen2022boxer}
\citation{nguyen2022boxer}
\citation{zhu2021deformable}
\citation{nguyen2022boxer}
\citation{zhu2021deformable}
\citation{li2022vitdet}
\citation{nguyen2022boxer,cheng2022mask2former}
\citation{liu2021swintransformer}
\citation{li2022vitdet}
\citation{nguyen2022boxer,cheng2022mask2former}
\citation{liu2021swintransformer}
\citation{wei2016ssd,tsung2017fpn,zhu2021deformable}
\citation{li2022vitdet,chen2022uvit}
\citation{vaswani2017transformer}
\@LN@col{1}
\@LN{161}{2}
\@LN{162}{2}
\@writefile{brf}{\backcite{he2022mae}{{3}{2}{section.2}}}
\@LN{163}{2}
\@LN{164}{2}
\@LN{165}{2}
\@LN{166}{2}
\@writefile{brf}{\backcite{lin2023plaindetr}{{3}{2}{section.2}}}
\@LN{167}{2}
\@LN{168}{2}
\@LN{169}{2}
\@LN{170}{2}
\@writefile{brf}{\backcite{jia2023hybridmatching}{{3}{2}{section.2}}}
\@LN{171}{2}
\@LN{172}{2}
\@writefile{brf}{\backcite{nguyen2022boxer}{{3}{2}{section.2}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{3}{2}{section.2}}}
\@LN{173}{2}
\@LN{174}{2}
\@LN{175}{2}
\@LN{176}{2}
\@LN{177}{2}
\@LN{178}{2}
\@LN{179}{2}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Background}{3}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{3}{\hskip -1em.~Background}{section.3}{}}
\newlabel{sec:background@cref}{{[section][3][]3}{[1][3][]3}}
\@LN{180}{2}
\@writefile{brf}{\backcite{li2022vitdet}{{3}{3}{section.3}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{3}{3}{section.3}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{3}{3}{section.3}}}
\@LN{181}{2}
\@LN{182}{2}
\@LN{183}{2}
\@LN{184}{2}
\@writefile{brf}{\backcite{nguyen2022boxer}{{3}{3}{section.3}}}
\@LN{185}{2}
\@writefile{brf}{\backcite{zhu2021deformable}{{3}{3}{section.3}}}
\@LN{186}{2}
\@LN{187}{2}
\@LN{188}{2}
\@writefile{toc}{\contentsline {paragraph}{Multi-head Box-Attention.}{3}{section*.2}\protected@file@percent }
\@LN{189}{2}
\@LN{190}{2}
\@LN{191}{2}
\@LN{192}{2}
\@LN{193}{2}
\@LN{194}{2}
\@LN{195}{2}
\@LN{196}{2}
\@LN{197}{2}
\@LN{198}{2}
\@LN{199}{2}
\@LN{200}{2}
\@LN{201}{2}
\@LN{202}{2}
\@LN{203}{2}
\@LN{204}{2}
\@LN{205}{2}
\@LN{206}{2}
\@LN{207}{2}
\@LN{208}{2}
\@LN{209}{2}
\@LN@col{2}
\@LN{210}{2}
\@LN{211}{2}
\@LN{212}{2}
\@LN{213}{2}
\@LN{214}{2}
\@LN{215}{2}
\@LN{216}{2}
\@LN{217}{2}
\@LN{218}{2}
\@LN{219}{2}
\@writefile{brf}{\backcite{nguyen2022boxer}{{3}{3}{equation.3.5}}}
\@LN{220}{2}
\@LN{221}{2}
\@writefile{toc}{\contentsline {paragraph}{Multi-head Deformable Attention.}{3}{section*.3}\protected@file@percent }
\@LN{222}{2}
\@LN{223}{2}
\@LN{224}{2}
\@LN{225}{2}
\@LN{226}{2}
\@LN{227}{2}
\@LN{228}{2}
\@LN{229}{2}
\@LN{230}{2}
\@LN{231}{2}
\@LN{232}{2}
\@LN{233}{2}
\@LN{234}{2}
\@LN{235}{2}
\@LN{236}{2}
\@LN{237}{2}
\@LN{238}{2}
\@LN{239}{2}
\@LN{240}{2}
\@LN{241}{2}
\@LN{242}{2}
\@LN{243}{2}
\@LN{244}{2}
\@writefile{brf}{\backcite{zhu2021deformable}{{3}{3}{equation.3.8}}}
\@LN{245}{2}
\@LN{246}{2}
\@LN{247}{2}
\@LN{248}{2}
\@LN{249}{2}
\@LN{250}{2}
\@LN{251}{2}
\@LN{252}{2}
\@LN{253}{2}
\citation{zhu2021deformable}
\citation{vaswani2017transformer}
\citation{nguyen2022boxer}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {Object detection architectures. Left:} The plain-backbone detector from\nobreakspace  {}\cite  {li2022vitdet} whose input (denoted in the dashed region) are multi-scale features. \textbf  {Middle:} State-of-the-art end-to-end detectors\nobreakspace  {}\cite  {nguyen2022boxer,cheng2022mask2former} utilize a hierarchical backbone (\emph  {i.e}\onedot  , Swin\nobreakspace  {}\cite  {liu2021swintransformer}) to create multi-scale inputs. \textbf  {Right:} Our simple single-scale detector following the end-to-end framework. Where existing detectors require feature pyramids to be effective, we propose a plain detector, SimPLR\xspace  , whose backbone and detection head are non-hierarchical and operate on a single-scale feature map. The plain detector, SimPLR\xspace  , achieves on par or even better performance compared to hierarchical and/or multi-scale counterparts while being more efficient. \relax }}{4}{figure.caption.4}\protected@file@percent }
\@writefile{brf}{\backcite{li2022vitdet}{{4}{2}{figure.caption.4}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{4}{2}{figure.caption.4}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{4}{2}{figure.caption.4}}}
\@writefile{brf}{\backcite{liu2021swintransformer}{{4}{2}{figure.caption.4}}}
\newlabel{fig:compare}{{2}{4}{\textbf {Object detection architectures. Left:} The plain-backbone detector from~\cite {li2022vitdet} whose input (denoted in the dashed region) are multi-scale features. \textbf {Middle:} State-of-the-art end-to-end detectors~\cite {nguyen2022boxer,cheng2022mask2former} utilize a hierarchical backbone (\ie , Swin~\cite {liu2021swintransformer}) to create multi-scale inputs. \textbf {Right:} Our simple single-scale detector following the end-to-end framework. Where existing detectors require feature pyramids to be effective, we propose a plain detector, \ours , whose backbone and detection head are non-hierarchical and operate on a single-scale feature map. The plain detector, \ours , achieves on par or even better performance compared to hierarchical and/or multi-scale counterparts while being more efficient. \relax }{figure.caption.4}{}}
\newlabel{fig:compare@cref}{{[figure][2][]2}{[1][3][]4}}
\@LN@col{1}
\@LN{254}{3}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}SimPLR\xspace  : A Simple and Plain Detector}{4}{section.4}\protected@file@percent }
\newlabel{sec:simplr}{{4}{4}{\hskip -1em.~\ours : A Simple and Plain Detector}{section.4}{}}
\newlabel{sec:simplr@cref}{{[section][4][]4}{[1][3][]4}}
\@LN{255}{3}
\@writefile{brf}{\backcite{tsung2017fpn}{{4}{4}{section.4}}}
\@writefile{brf}{\backcite{wei2016ssd}{{4}{4}{section.4}}}
\@writefile{brf}{\backcite{zhu2021deformable}{{4}{4}{section.4}}}
\@LN{256}{3}
\@LN{257}{3}
\@LN{258}{3}
\@LN{259}{3}
\@LN{260}{3}
\@LN{261}{3}
\@writefile{brf}{\backcite{chen2022uvit}{{4}{4}{section.4}}}
\@writefile{brf}{\backcite{li2022vitdet}{{4}{4}{section.4}}}
\@LN{262}{3}
\@writefile{brf}{\backcite{vaswani2017transformer}{{4}{4}{section.4}}}
\@LN{263}{3}
\@LN{264}{3}
\@LN{265}{3}
\@LN{266}{3}
\@LN{267}{3}
\@LN{268}{3}
\@LN{269}{3}
\@LN{270}{3}
\@LN{271}{3}
\@LN{272}{3}
\@LN{273}{3}
\@LN{274}{3}
\@LN{275}{3}
\@LN{276}{3}
\@LN{277}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Scale-aware attention}{4}{subsection.4.1}\protected@file@percent }
\@LN{278}{3}
\@LN{279}{3}
\@LN{280}{3}
\@LN{281}{3}
\@LN{282}{3}
\@LN@col{2}
\@LN{283}{3}
\@LN{284}{3}
\@LN{285}{3}
\@LN{286}{3}
\@LN{287}{3}
\@LN{288}{3}
\@LN{289}{3}
\@LN{290}{3}
\@LN{291}{3}
\@writefile{brf}{\backcite{zhu2021deformable}{{4}{4.1}{subsection.4.1}}}
\@LN{292}{3}
\@LN{293}{3}
\@LN{294}{3}
\@LN{295}{3}
\@LN{296}{3}
\@writefile{brf}{\backcite{vaswani2017transformer}{{4}{4.1}{subsection.4.1}}}
\@LN{297}{3}
\@LN{298}{3}
\@LN{299}{3}
\@writefile{brf}{\backcite{nguyen2022boxer}{{4}{4.1}{subsection.4.1}}}
\@LN{300}{3}
\@LN{301}{3}
\@LN{302}{3}
\@LN{303}{3}
\@LN{304}{3}
\@LN{305}{3}
\@LN{306}{3}
\@LN{307}{3}
\@LN{308}{3}
\@LN{309}{3}
\@LN{310}{3}
\@LN{311}{3}
\@LN{312}{3}
\@LN{313}{3}
\@LN{314}{3}
\@LN{315}{3}
\citation{nguyen2022boxer}
\citation{li2022vitdet}
\citation{li2022vitdet}
\citation{he2022mae}
\citation{peng2022beitv2}
\citation{he2022mae,zhai2022scalingvit,dehghani2023scalingvit22b}
\citation{kirillov2019panoptic}
\citation{cheng2022mask2former}
\citation{cheng2022mask2former}
\citation{nguyen2022boxer}
\citation{cheng2022mask2former}
\@LN@col{1}
\@LN{316}{4}
\@LN{317}{4}
\@LN{318}{4}
\@LN{319}{4}
\@LN{320}{4}
\@LN{321}{4}
\@LN{322}{4}
\@LN{323}{4}
\@LN{324}{4}
\@LN{325}{4}
\@LN{326}{4}
\@LN{327}{4}
\@LN{328}{4}
\@LN{329}{4}
\@LN{330}{4}
\@LN{331}{4}
\@LN{332}{4}
\@LN{333}{4}
\@LN{334}{4}
\@LN{335}{4}
\@LN{336}{4}
\@LN{337}{4}
\@LN{338}{4}
\@LN{339}{4}
\@LN{340}{4}
\@LN{341}{4}
\@LN{342}{4}
\@LN{343}{4}
\@LN{344}{4}
\@LN{345}{4}
\@LN{346}{4}
\@LN{347}{4}
\@LN{348}{4}
\@LN{349}{4}
\@LN{350}{4}
\@LN{351}{4}
\@LN{352}{4}
\@LN{353}{4}
\@LN{354}{4}
\@LN{355}{4}
\@LN{356}{4}
\@LN{357}{4}
\@LN{358}{4}
\@LN{359}{4}
\@LN{360}{4}
\@LN{361}{4}
\@LN{362}{4}
\@LN{363}{4}
\@LN{364}{4}
\@LN{365}{4}
\@LN{366}{4}
\@LN@col{2}
\@LN{367}{4}
\@LN{368}{4}
\@LN{369}{4}
\@LN{370}{4}
\@LN{371}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Network Architecture}{5}{subsection.4.2}\protected@file@percent }
\@LN{372}{4}
\@writefile{brf}{\backcite{nguyen2022boxer}{{5}{4.2}{subsection.4.2}}}
\@LN{373}{4}
\@LN{374}{4}
\@LN{375}{4}
\@writefile{brf}{\backcite{li2022vitdet}{{5}{4.2}{subsection.4.2}}}
\@LN{376}{4}
\@LN{377}{4}
\@LN{378}{4}
\@LN{379}{4}
\@LN{380}{4}
\@LN{381}{4}
\@LN{382}{4}
\@LN{383}{4}
\@LN{384}{4}
\@LN{385}{4}
\@LN{386}{4}
\@LN{387}{4}
\@LN{388}{4}
\@LN{389}{4}
\@LN{390}{4}
\@LN{391}{4}
\@writefile{brf}{\backcite{li2022vitdet}{{5}{4.2}{subsection.4.2}}}
\@LN{392}{4}
\@LN{393}{4}
\@LN{394}{4}
\@LN{395}{4}
\@LN{396}{4}
\@LN{397}{4}
\@LN{398}{4}
\@LN{399}{4}
\@LN{400}{4}
\@LN{401}{4}
\@writefile{brf}{\backcite{he2022mae}{{5}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{peng2022beitv2}{{5}{4.2}{subsection.4.2}}}
\@LN{402}{4}
\@LN{403}{4}
\@LN{404}{4}
\@writefile{brf}{\backcite{dehghani2023scalingvit22b}{{5}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{he2022mae}{{5}{4.2}{subsection.4.2}}}
\@writefile{brf}{\backcite{zhai2022scalingvit}{{5}{4.2}{subsection.4.2}}}
\@LN{405}{4}
\@LN{406}{4}
\@LN{407}{4}
\@LN{408}{4}
\@writefile{brf}{\backcite{kirillov2019panoptic}{{5}{4.2}{subsection.4.2}}}
\@LN{409}{4}
\@LN{410}{4}
\@LN{411}{4}
\@writefile{brf}{\backcite{cheng2022mask2former}{{5}{4.2}{subsection.4.2}}}
\@LN{412}{4}
\@LN{413}{4}
\@LN{414}{4}
\@LN{415}{4}
\@LN{416}{4}
\@writefile{brf}{\backcite{cheng2022mask2former}{{5}{4.2}{subsection.4.2}}}
\@LN{417}{4}
\@LN{418}{4}
\citation{lin2014mscoco}
\citation{he2022mae}
\citation{nguyen2022boxer}
\citation{loshchilov2019adamw}
\citation{dosovitskiy2021vit}
\citation{shiasi2021lsjitter}
\citation{nguyen2022boxer}
\citation{li2022vitdet}
\citation{zhu2021deformable}
\citation{lin2023plaindetr}
\citation{lin2023plaindetr}
\citation{lin2023plaindetr}
\citation{li2022vitdet}
\citation{li2022vitdet}
\citation{nguyen2022boxer}
\citation{nguyen2022boxer}
\citation{zhu2021deformable}
\citation{li2022vitdet}
\citation{lin2023plaindetr}
\@LN@col{1}
\@LN{419}{5}
\@LN{420}{5}
\@LN{421}{5}
\@LN{422}{5}
\@LN{423}{5}
\@LN{424}{5}
\@LN{425}{5}
\@writefile{brf}{\backcite{nguyen2022boxer}{{6}{4.2}{subsection.4.2}}}
\@LN{426}{5}
\@LN{427}{5}
\@writefile{brf}{\backcite{cheng2022mask2former}{{6}{4.2}{subsection.4.2}}}
\@LN{428}{5}
\@LN{429}{5}
\@LN{430}{5}
\@LN{431}{5}
\@LN{432}{5}
\@LN{433}{5}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments}{6}{section.5}\protected@file@percent }
\newlabel{sec:experiments}{{5}{6}{\hskip -1em.~Experiments}{section.5}{}}
\newlabel{sec:experiments@cref}{{[section][5][]5}{[1][6][]6}}
\@LN{434}{5}
\@writefile{brf}{\backcite{lin2014mscoco}{{6}{5}{section.5}}}
\@LN{435}{5}
\@LN{436}{5}
\@LN{437}{5}
\@LN{438}{5}
\@LN{439}{5}
\@writefile{brf}{\backcite{he2022mae}{{6}{5}{section.5}}}
\@LN{440}{5}
\@LN{441}{5}
\@LN{442}{5}
\@LN{443}{5}
\@writefile{brf}{\backcite{nguyen2022boxer}{{6}{5}{section.5}}}
\@LN{444}{5}
\@writefile{brf}{\backcite{loshchilov2019adamw}{{6}{5}{section.5}}}
\@LN{445}{5}
\@LN{446}{5}
\@LN{447}{5}
\@LN{448}{5}
\@writefile{brf}{\backcite{dosovitskiy2021vit}{{6}{5}{section.5}}}
\@LN{449}{5}
\@writefile{brf}{\backcite{shiasi2021lsjitter}{{6}{5}{section.5}}}
\@LN{450}{5}
\@LN{451}{5}
\@LN{452}{5}
\@writefile{brf}{\backcite{nguyen2022boxer}{{6}{5}{section.5}}}
\@LN{453}{5}
\@writefile{brf}{\backcite{li2022vitdet}{{6}{5}{section.5}}}
\@LN{454}{5}
\@LN{455}{5}
\@LN{456}{5}
\@LN{457}{5}
\@LN{458}{5}
\@LN{459}{5}
\@LN{460}{5}
\@LN{461}{5}
\@LN{462}{5}
\@LN{463}{5}
\@LN{464}{5}
\@LN{465}{5}
\@LN{466}{5}
\@LN{467}{5}
\@LN{468}{5}
\@LN{469}{5}
\@LN{470}{5}
\@LN@col{2}
\@writefile{brf}{\backcite{lin2023plaindetr}{{6}{\caption@xref {??}{ on input line 25}}{table.caption.6}}}
\@writefile{brf}{\backcite{lin2023plaindetr}{{6}{\caption@xref {??}{ on input line 26}}{table.caption.6}}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {SimPLR\xspace  is an effective plain detector.} All methods use ViT-B as backbone. Methods that take feature pyramids as input employ SimpleFPN with ViT from \cite  {li2022vitdet}. Our plain detector, SimPLR\xspace  , shows competitive performance compared to multi-scale alternatives, while being more efficient in terms of FLOPs, training memory and faster during inference. Training memory is reported as relative to SimPLR\xspace  (SAD: scale-aware deformable attention; SAB: scale-aware box-attention).\relax }}{6}{table.caption.6}\protected@file@percent }
\@writefile{brf}{\backcite{li2022vitdet}{{6}{1}{table.caption.6}}}
\newlabel{tab:compare}{{1}{6}{\textbf {\ours is an effective plain detector.} All methods use ViT-B as backbone. Methods that take feature pyramids as input employ SimpleFPN with ViT from \cite {li2022vitdet}. Our plain detector, \ours , shows competitive performance compared to multi-scale alternatives, while being more efficient in terms of FLOPs, training memory and faster during inference. Training memory is reported as relative to \ours (SAD: scale-aware deformable attention; SAB: scale-aware box-attention).\relax }{table.caption.6}{}}
\newlabel{tab:compare@cref}{{[table][1][]1}{[1][6][]6}}
\@LN{471}{5}
\@LN{472}{5}
\@LN{473}{5}
\@LN{474}{5}
\@LN{475}{5}
\@writefile{brf}{\backcite{zhu2021deformable}{{6}{5}{section.5}}}
\@LN{476}{5}
\@LN{477}{5}
\@writefile{brf}{\backcite{lin2023plaindetr}{{6}{5}{section.5}}}
\@LN{478}{5}
\@LN{479}{5}
\@LN{480}{5}
\@LN{481}{5}
\@LN{482}{5}
\@LN{483}{5}
\@LN{484}{5}
\@writefile{brf}{\backcite{zhu2021deformable}{{6}{5}{table.caption.7}}}
\@LN{485}{5}
\@LN{486}{5}
\@writefile{brf}{\backcite{li2022vitdet}{{6}{5}{table.caption.7}}}
\@LN{487}{5}
\@LN{488}{5}
\@LN{489}{5}
\@LN{490}{5}
\@LN{491}{5}
\@LN{492}{5}
\@LN{493}{5}
\@LN{494}{5}
\@LN{495}{5}
\@LN{496}{5}
\@LN{497}{5}
\@LN{498}{5}
\@LN{499}{5}
\@LN{500}{5}
\@LN{501}{5}
\citation{nguyen2022boxer}
\citation{he2022mae}
\citation{peng2022beitv2}
\citation{cheng2022mask2former}
\citation{liu2021swintransformer}
\citation{fan2021mvit}
\citation{liu2021swintransformer}
\citation{cheng2022mask2former}
\citation{fan2021mvit}
\citation{nguyen2022boxer}
\citation{li2022vitdet}
\citation{chen2022uvit}
\citation{lin2023plaindetr}
\citation{liu2021swintransformer}
\citation{cheng2022mask2former}
\citation{fan2021mvit}
\citation{li2022vitdet}
\citation{li2022vitdet}
\citation{li2022vitdet}
\citation{cheng2021maskformer}
\citation{cheng2022mask2former}
\citation{cheng2022mask2former}
\newlabel{tab:strat}{{2a}{7}{\textbf {Scale-aware attention.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{tab:strat@cref}{{[subtable][1][2]2a}{[1][6][]7}}
\newlabel{sub@tab:strat}{{a}{7}{\textbf {Scale-aware attention.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{sub@tab:strat@cref}{{[subtable][1][2]2a}{[1][6][]7}}
\newlabel{tab:window_size}{{2b}{7}{\textbf {Window size.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{tab:window_size@cref}{{[subtable][2][2]2b}{[1][6][]7}}
\newlabel{sub@tab:window_size}{{b}{7}{\textbf {Window size.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{sub@tab:window_size@cref}{{[subtable][2][2]2b}{[1][6][]7}}
\newlabel{tab:num_scale}{{2c}{7}{\textbf {Number of window scales}.\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{tab:num_scale@cref}{{[subtable][3][2]2c}{[1][6][]7}}
\newlabel{sub@tab:num_scale}{{c}{7}{\textbf {Number of window scales}.\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{sub@tab:num_scale@cref}{{[subtable][3][2]2c}{[1][6][]7}}
\newlabel{tab:feat_scale}{{2d}{7}{\textbf {Scales of input features.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{tab:feat_scale@cref}{{[subtable][4][2]2d}{[1][6][]7}}
\newlabel{sub@tab:feat_scale}{{d}{7}{\textbf {Scales of input features.}\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{sub@tab:feat_scale@cref}{{[subtable][4][2]2d}{[1][6][]7}}
\newlabel{fig:attn_vis}{{2e}{7}{Visualization of scale distribution learnt in \textbf {multi-head adaptive-scale attention} of object proposals. Objects are classified into \emph {small}, \emph {medium}, and \emph {large} based on their area.\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{fig:attn_vis@cref}{{[subtable][5][2]2e}{[1][6][]7}}
\newlabel{sub@fig:attn_vis}{{e}{7}{Visualization of scale distribution learnt in \textbf {multi-head adaptive-scale attention} of object proposals. Objects are classified into \emph {small}, \emph {medium}, and \emph {large} based on their area.\caption@thelabel \relax }{table.caption.7}{}}
\newlabel{sub@fig:attn_vis@cref}{{[subtable][5][2]2e}{[1][6][]7}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  \textbf  {Ablation of scale-aware attention} in SimPLR\xspace  using a plain ViT backbone on COCO\nobreakspace  {}{\texttt  {val}}\xspace  . \textbf  {Table (a-d):} Compared to the na\"ive baseline, which employs BoxeR and box-attention \citep  {nguyen2022boxer} with \textit  {single-scale} features, our plain detector, SimPLR\xspace  , with scale-aware attention improves the performance consistently for all settings, default setting highlighted. \textbf  {Figure e:} our adaptive-scale attention captures different scale distribution in its attention heads based on the context of query vectors. Specifically, queries of \emph  {small} objects tends to focus on reference windows of small scales (\emph  {i.e}\onedot  , mainly \(32\times 32\)), while query vectors of \emph  {medium} and \emph  {large} objects distribute more attention computation into larger reference windows.\relax }}{7}{table.caption.7}\protected@file@percent }
\newlabel{tab:det_ablation}{{2}{7}{\textbf {Ablation of scale-aware attention} in \ours using a plain ViT backbone on COCO~\val . \textbf {Table (a-d):} Compared to the na\"ive baseline, which employs BoxeR and box-attention \citep {nguyen2022boxer} with \textit {single-scale} features, our plain detector, \ours , with scale-aware attention improves the performance consistently for all settings, default setting highlighted. \textbf {Figure e:} our adaptive-scale attention captures different scale distribution in its attention heads based on the context of query vectors. Specifically, queries of \emph {small} objects tends to focus on reference windows of small scales (\ie , mainly \(32\times 32\)), while query vectors of \emph {medium} and \emph {large} objects distribute more attention computation into larger reference windows.\relax }{table.caption.7}{}}
\newlabel{tab:det_ablation@cref}{{[table][2][]2}{[1][6][]7}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{7}{2}{table.caption.7}}}
\@LN@col{1}
\@LN{502}{6}
\@LN{503}{6}
\@writefile{brf}{\backcite{lin2023plaindetr}{{7}{5}{table.caption.7}}}
\@LN{504}{6}
\@LN{505}{6}
\@LN{506}{6}
\@LN{507}{6}
\@LN{508}{6}
\@LN{509}{6}
\@LN{510}{6}
\@LN{511}{6}
\@LN{512}{6}
\@writefile{brf}{\backcite{nguyen2022boxer}{{7}{5}{table.caption.7}}}
\@LN{513}{6}
\@LN{514}{6}
\@LN{515}{6}
\@LN{516}{6}
\@LN{517}{6}
\@LN{518}{6}
\@LN{519}{6}
\@LN{520}{6}
\@LN{521}{6}
\@LN{522}{6}
\@LN{523}{6}
\@LN{524}{6}
\@LN{525}{6}
\@LN{526}{6}
\@LN{527}{6}
\@LN{528}{6}
\@LN{529}{6}
\@LN{530}{6}
\@LN{531}{6}
\@LN{532}{6}
\@LN@col{2}
\@LN{533}{6}
\@LN{534}{6}
\@LN{535}{6}
\@LN{536}{6}
\@LN{537}{6}
\@LN{538}{6}
\@LN{539}{6}
\@LN{540}{6}
\@LN{541}{6}
\@LN{542}{6}
\@LN{543}{6}
\@LN{544}{6}
\@LN{545}{6}
\@LN{546}{6}
\@LN{547}{6}
\@LN{548}{6}
\@LN{549}{6}
\@LN{550}{6}
\@LN{551}{6}
\@LN{552}{6}
\@writefile{brf}{\backcite{he2022mae}{{7}{5}{table.caption.7}}}
\@writefile{brf}{\backcite{peng2022beitv2}{{7}{5}{table.caption.7}}}
\@LN{553}{6}
\@LN{554}{6}
\@LN{555}{6}
\@LN{556}{6}
\@writefile{brf}{\backcite{cheng2022mask2former}{{7}{5}{table.caption.7}}}
\@LN{557}{6}
\@writefile{brf}{\backcite{liu2021swintransformer}{{7}{5}{table.caption.7}}}
\@LN{558}{6}
\@writefile{brf}{\backcite{fan2021mvit}{{7}{5}{table.caption.7}}}
\@LN{559}{6}
\@LN{560}{6}
\@LN{561}{6}
\@LN{562}{6}
\@LN{563}{6}
\bibstyle{ieeenat_fullname}
\bibdata{simplr}
\bibcite{bao2022beit}{{1}{2022}{{Bao et~al.}}{{Bao, Dong, Piao, and Wei}}}
\@writefile{brf}{\backcite{liu2021swintransformer}{{8}{\caption@xref {??}{ on input line 174}}{table.caption.8}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{8}{\caption@xref {??}{ on input line 175}}{table.caption.8}}}
\@writefile{brf}{\backcite{fan2021mvit}{{8}{\caption@xref {??}{ on input line 176}}{table.caption.8}}}
\@writefile{brf}{\backcite{nguyen2022boxer}{{8}{\caption@xref {??}{ on input line 177}}{table.caption.8}}}
\@writefile{brf}{\backcite{li2022vitdet}{{8}{\caption@xref {??}{ on input line 178}}{table.caption.8}}}
\@writefile{brf}{\backcite{chen2022uvit}{{8}{\caption@xref {??}{ on input line 181}}{table.caption.8}}}
\@writefile{brf}{\backcite{lin2023plaindetr}{{8}{\caption@xref {??}{ on input line 182}}{table.caption.8}}}
\@writefile{brf}{\backcite{liu2021swintransformer}{{8}{\caption@xref {??}{ on input line 188}}{table.caption.8}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{8}{\caption@xref {??}{ on input line 189}}{table.caption.8}}}
\@writefile{brf}{\backcite{fan2021mvit}{{8}{\caption@xref {??}{ on input line 190}}{table.caption.8}}}
\@writefile{brf}{\backcite{li2022vitdet}{{8}{\caption@xref {??}{ on input line 191}}{table.caption.8}}}
\@writefile{brf}{\backcite{li2022vitdet}{{8}{\caption@xref {??}{ on input line 199}}{table.caption.8}}}
\@writefile{brf}{\backcite{li2022vitdet}{{8}{\caption@xref {??}{ on input line 200}}{table.caption.8}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  { State-of-the-art comparison and scaling behavior for object detection and instance segmentation.} We compare methods using feature pyramids (\emph  {top} row) \emph  {vs}\onedot  single-scale (\emph  {bottom} row) on COCO {\texttt  {val}}\xspace  . Backbones with MAE pre-trained on ImageNet-1K while others pre-trained on ImageNet-22K. Methods in \textcolor {gray}{gray color} are with convolution-based detection head. (n/a: entry is not available). Models of larger sizes are grouped with \emph  {darker} \textcolor {orange}{orange color}. SimPLR\xspace  indicates good scaling behavior. With only single-scale features, SimPLR\xspace  shows strong performance compared to multi-scale detectors including transformer-based detectors like Mask2Former, while being faster.\relax }}{8}{table.caption.8}\protected@file@percent }
\newlabel{tab:det_main}{{3}{8}{\textbf { State-of-the-art comparison and scaling behavior for object detection and instance segmentation.} We compare methods using feature pyramids (\emph {top} row) \vs single-scale (\emph {bottom} row) on COCO \val . Backbones with MAE pre-trained on ImageNet-1K while others pre-trained on ImageNet-22K. Methods in \textcolor {gray}{gray color} are with convolution-based detection head. (n/a: entry is not available). Models of larger sizes are grouped with \emph {darker} \textcolor {orange}{orange color}. \ours indicates good scaling behavior. With only single-scale features, \ours shows strong performance compared to multi-scale detectors including transformer-based detectors like Mask2Former, while being faster.\relax }{table.caption.8}{}}
\newlabel{tab:det_main@cref}{{[table][3][]3}{[1][7][]8}}
\@LN@col{1}
\@writefile{brf}{\backcite{cheng2021maskformer}{{8}{\caption@xref {??}{ on input line 223}}{table.caption.9}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{8}{\caption@xref {??}{ on input line 224}}{table.caption.9}}}
\@writefile{brf}{\backcite{cheng2022mask2former}{{8}{\caption@xref {??}{ on input line 229}}{table.caption.9}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \textbf  {State-of-the-art comparison and scaling behavior for panoptic segmentation.} We compare between methods using feature pyramids (\emph  {top} row) \emph  {vs}\onedot  single-scale (\emph  {bottom} row) on COCO\nobreakspace  {}{\texttt  {val}}\xspace  . Models of larger sizes are with \emph  {darker} \textcolor {orange}{orange color}. SimPLR\xspace  shows better results when scaling to larger backbones, while being faster with single-scale input.\relax }}{8}{table.caption.9}\protected@file@percent }
\newlabel{tab:panoptic}{{4}{8}{\textbf {State-of-the-art comparison and scaling behavior for panoptic segmentation.} We compare between methods using feature pyramids (\emph {top} row) \vs single-scale (\emph {bottom} row) on COCO~\val . Models of larger sizes are with \emph {darker} \textcolor {orange}{orange color}. \ours shows better results when scaling to larger backbones, while being faster with single-scale input.\relax }{table.caption.9}{}}
\newlabel{tab:panoptic@cref}{{[table][4][]4}{[1][7][]8}}
\@LN{564}{7}
\@LN{565}{7}
\@LN{566}{7}
\@LN{567}{7}
\@LN{568}{7}
\@LN{569}{7}
\@LN{570}{7}
\@LN@col{2}
\@LN{571}{7}
\@LN{572}{7}
\@LN{573}{7}
\@LN{574}{7}
\@LN{575}{7}
\@LN{576}{7}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion}{8}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{8}{\hskip -1em.~Conclusion}{section.6}{}}
\newlabel{sec:conclusion@cref}{{[section][6][]6}{[1][8][]8}}
\@LN{577}{7}
\@LN{578}{7}
\@LN{579}{7}
\@LN{580}{7}
\@LN{581}{7}
\@LN{582}{7}
\@LN{583}{7}
\@LN{584}{7}
\@LN{585}{7}
\@LN{586}{7}
\@LN{587}{7}
\@LN{588}{7}
\@LN{589}{7}
\@LN{590}{7}
\@LN{591}{7}
\bibcite{brown2020gpt3}{{2}{2020}{{Brown et~al.}}{{Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Amanda~Askell, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei}}}
\bibcite{nicolas2020detr}{{3}{2020}{{Carion et~al.}}{{Carion, Massa, Synnaeve, Usunier, Kirillov, and Zagoruyko}}}
\bibcite{chen2020igpt}{{4}{2020{}}{{Chen et~al.}}{{Chen, Radford, Child, Wu, Jun, Dhariwal, Luan, and Sutskever}}}
\bibcite{chen2020simclr}{{5}{2020{}}{{Chen et~al.}}{{Chen, Kornblith, Norouzi, and Hinton}}}
\bibcite{chen2022uvit}{{6}{2022}{{Chen et~al.}}{{Chen, Du, Yang, Beyer, Zhai, Lin, Chen, Li, Song, Wang, and Zhou}}}
\bibcite{cheng2021maskformer}{{7}{2021}{{Cheng et~al.}}{{Cheng, Schwing, and Kirillov}}}
\bibcite{cheng2022mask2former}{{8}{2022}{{Cheng et~al.}}{{Cheng, Misra, Schwing, Kirillov, and Girdhar}}}
\bibcite{dehghani2023scalingvit22b}{{9}{2023}{{Dehghani et~al.}}{{Dehghani, Djolonga, Mustafa, and et~al.}}}
\bibcite{deng2009imagenet}{{10}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li, and Fei-Fei}}}
\bibcite{devlin2019bert}{{11}{2019}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{dong2021solq}{{12}{2021}{{Dong et~al.}}{{Dong, Zeng, Wang, Zhang, and Wei}}}
\bibcite{dosovitskiy2021vit}{{13}{2021}{{Dosovitskiy et~al.}}{{Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby}}}
\bibcite{fan2021mvit}{{14}{2021}{{Fan et~al.}}{{Fan, Xiong, Mangalam, Li, Yan, Malik, and Feichtenhofer}}}
\bibcite{shiasi2021lsjitter}{{15}{2021}{{Ghiasi et~al.}}{{Ghiasi, Cui, Srinivas, Qian, Lin, Cubuk, Le, and Zoph}}}
\bibcite{girshick2014rcnn}{{16}{2014}{{Girshick et~al.}}{{Girshick, Donahue, Darrell, and Malik}}}
\bibcite{kaiming2016resnet}{{17}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{he2017maskrcnn}{{18}{2017}{{He et~al.}}{{He, Gkioxari, Dollár, and Girshick}}}
\bibcite{he2022mae}{{19}{2022}{{He et~al.}}{{He, Chen, Xie, Li, Doll{\'a}r, and Girshick}}}
\bibcite{heo2021rethinkingvit}{{20}{2021}{{Heo et~al.}}{{Heo, Yun, Han, Chun, Choe, and Oh}}}
\bibcite{huang2017densenet}{{21}{2017}{{Huang et~al.}}{{Huang, Liu, van~der Maaten, and Weinberger}}}
\bibcite{jia2023hybridmatching}{{22}{2023}{{Jia et~al.}}{{Jia, Yuan, He, Wu, Yu, Lin, Sun, Zhang, and Hu}}}
\bibcite{kirillov2019panoptic}{{23}{2019}{{Kirillov et~al.}}{{Kirillov, He, Girshick, Rother, and Dollar}}}
\bibcite{lecun95convolutional}{{24}{1995}{{LeCun and Bengio}}{{}}}
\bibcite{li2023maskdino}{{25}{2023}{{Li et~al.}}{{Li, Zhang, xu, Liu, Zhang, Ni, and Shum}}}
\bibcite{li2022vitdet}{{26}{2022}{{Li et~al.}}{{Li, Mao, Girshick, and He}}}
\bibcite{lin2014mscoco}{{27}{2014}{{Lin et~al.}}{{Lin, Maire, Belongie, Bourdev, Girshick, Hays, Perona, Ramanan, Doll{\'{a}}r, and Zitnick}}}
\bibcite{tsung2017fpn}{{28}{2017}{{{Lin} et~al.}}{{{Lin}, {Dollár}, {Girshick}, {He}, {Hariharan}, and {Belongie}}}}
\bibcite{lin2023plaindetr}{{29}{2023}{{Lin et~al.}}{{Lin, Yuan, Zhang, Li, Zheng, and Hu}}}
\bibcite{wei2016ssd}{{30}{2016}{{Liu et~al.}}{{Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and Berg}}}
\bibcite{liu2021swintransformer}{{31}{2021}{{Liu et~al.}}{{Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo}}}
\bibcite{loshchilov2019adamw}{{32}{2019}{{Loshchilov and Hutter}}{{}}}
\bibcite{nguyen2022boxer}{{33}{2022}{{Nguyen et~al.}}{{Nguyen, Ju, Booij, Oswald, and Snoek}}}
\@LN@col{1}
\@LN{592}{8}
\@LN{593}{8}
\@LN{594}{8}
\@LN{595}{8}
\@LN{596}{8}
\@LN{597}{8}
\@LN{598}{8}
\@LN{599}{8}
\@LN{600}{8}
\@LN{601}{8}
\@LN{602}{8}
\@LN{603}{8}
\@LN{604}{8}
\@LN{605}{8}
\@LN{606}{8}
\@LN{607}{8}
\@LN{608}{8}
\@LN{609}{8}
\@LN{610}{8}
\@LN{611}{8}
\@LN{612}{8}
\@LN{613}{8}
\@LN{614}{8}
\@LN{615}{8}
\@LN{616}{8}
\@LN{617}{8}
\@LN{618}{8}
\@LN{619}{8}
\@LN{620}{8}
\@LN{621}{8}
\@LN{622}{8}
\@LN{623}{8}
\@LN{624}{8}
\@LN{625}{8}
\@LN{626}{8}
\@LN{627}{8}
\@LN{628}{8}
\@LN{629}{8}
\@LN{630}{8}
\@LN{631}{8}
\@LN{632}{8}
\@LN{633}{8}
\@LN{634}{8}
\@LN{635}{8}
\@LN{636}{8}
\@LN{637}{8}
\@LN{638}{8}
\@LN{639}{8}
\@LN{640}{8}
\@LN{641}{8}
\@LN{642}{8}
\@LN{643}{8}
\@LN{644}{8}
\@LN{645}{8}
\@LN{646}{8}
\@LN{647}{8}
\@LN@col{2}
\@LN{648}{8}
\@LN{649}{8}
\@LN{650}{8}
\@LN{651}{8}
\@LN{652}{8}
\@LN{653}{8}
\@LN{654}{8}
\@LN{655}{8}
\@LN{656}{8}
\@LN{657}{8}
\@LN{658}{8}
\@LN{659}{8}
\@LN{660}{8}
\@LN{661}{8}
\@LN{662}{8}
\@LN{663}{8}
\@LN{664}{8}
\@LN{665}{8}
\@LN{666}{8}
\@LN{667}{8}
\@LN{668}{8}
\@LN{669}{8}
\@LN{670}{8}
\@LN{671}{8}
\@LN{672}{8}
\@LN{673}{8}
\@LN{674}{8}
\@LN{675}{8}
\@LN{676}{8}
\@LN{677}{8}
\@LN{678}{8}
\@LN{679}{8}
\@LN{680}{8}
\@LN{681}{8}
\@LN{682}{8}
\@LN{683}{8}
\@LN{684}{8}
\@LN{685}{8}
\@LN{686}{8}
\@LN{687}{8}
\@LN{688}{8}
\@LN{689}{8}
\@LN{690}{8}
\@LN{691}{8}
\@LN{692}{8}
\@LN{693}{8}
\@LN{694}{8}
\@LN{695}{8}
\@LN{696}{8}
\@LN{697}{8}
\@LN{698}{8}
\@LN{699}{8}
\@LN{700}{8}
\@LN{701}{8}
\@LN{702}{8}
\@LN{703}{8}
\bibcite{peng2022beitv2}{{34}{2022}{{Peng et~al.}}{{Peng, Dong, Bao, Ye, and Wei}}}
\bibcite{ren2015faster_rcnn}{{35}{2015}{{Ren et~al.}}{{Ren, He, Girshick, and Sun}}}
\bibcite{simonyan2015vgg}{{36}{2015}{{Simonyan and Zisserman}}{{}}}
\bibcite{vaswani2017transformer}{{37}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{wang2021maxdeeplab}{{38}{2021{}}{{Wang et~al.}}{{Wang, Zhu, Adam, Yuille, and Chen}}}
\bibcite{wang2021pvit}{{39}{2021{}}{{Wang et~al.}}{{Wang, Xie, Li, Fan, Song, Liang, Lu, Luo, and Shao}}}
\bibcite{xie2017resnext}{{40}{2017}{{Xie et~al.}}{{Xie, Girshick, Doll{\'{a}}r, Tu, and He}}}
\bibcite{yu2022kmmask}{{41}{2022}{{Yu et~al.}}{{Yu, Wang, Qiao, Collins, Zhu, Adam, Yuille, and Chen}}}
\bibcite{zhai2022scalingvit}{{42}{2022}{{Zhai et~al.}}{{Zhai, Kolesnikov, Houlsby, and Beyer}}}
\bibcite{zhang2023dino}{{43}{2023}{{Zhang et~al.}}{{Zhang, Li, Liu, Zhang, Su, Zhu, Ni, and Shum}}}
\bibcite{zhang2021knet}{{44}{2021}{{Zhang et~al.}}{{Zhang, Pang, Chen, and Loy}}}
\bibcite{zhu2021deformable}{{45}{2021}{{Zhu et~al.}}{{Zhu, Su, Lu, Li, Wang, and Dai}}}
\@LN@col{1}
\@LN{704}{9}
\@LN{705}{9}
\@LN{706}{9}
\@LN{707}{9}
\@LN{708}{9}
\@LN{709}{9}
\@LN{710}{9}
\@LN{711}{9}
\@LN{712}{9}
\@LN{713}{9}
\@LN{714}{9}
\@LN{715}{9}
\@LN{716}{9}
\@LN{717}{9}
\@LN{718}{9}
\@LN{719}{9}
\@LN{720}{9}
\@LN{721}{9}
\@LN{722}{9}
\@LN{723}{9}
\@LN{724}{9}
\@LN{725}{9}
\@LN{726}{9}
\@LN{727}{9}
\@LN{728}{9}
\@LN{729}{9}
\@LN{730}{9}
\@LN{731}{9}
\@LN{732}{9}
\@LN{733}{9}
\@LN{734}{9}
\@LN{735}{9}
\@LN{736}{9}
\@LN{737}{9}
\@LN{738}{9}
\@LN{739}{9}
\@LN{740}{9}
\@LN{741}{9}
\@LN{742}{9}
\@LN{743}{9}
\@LN{744}{9}
\@LN@col{2}
\gdef \@abspage@last{10}
