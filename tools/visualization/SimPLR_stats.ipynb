{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duykien/home2/anaconda3/envs/ddn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/media/deepstorage01/home2/duykien/test/3D-ObjectDect/e2edet/utils/det3d/geometry.py:163: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def points_in_convex_polygon_jit(points, polygon, clockwise=True):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from e2edet.utils.configuration import load_yaml\n",
    "from e2edet.utils.general import get_root\n",
    "from e2edet.utils.box_ops import box_cxcywh_to_xyxy\n",
    "from e2edet.model import build_model\n",
    "from e2edet.module import build_matcher\n",
    "from e2edet.dataset import build_dataset\n",
    "from e2edet.dataset.coco import ConvertCocoPolysToMask\n",
    "from e2edet.dataset.helper.collate_fn import collate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"E2E_DATASETS\"] = \"/media/scratch1/duykien/data/coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(get_root(), \"..\", \"save/COCO-InstanceSegmentation/boxer2d_vit\")\n",
    "model_path = \"boxer2d_vit_b_w16_4g_5x_ss_lsj_final/boxer2d_vit_final.pth\"\n",
    "config_path = \"boxer2d_vit_b_w16_4g_5x_ss_lsj_final/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_src_permutation_idx(indices, num_references=4):\n",
    "    # permute predictions following indices\n",
    "    batch_idx = torch.cat(\n",
    "        [torch.full_like(src, i) for i, (src, _) in enumerate(indices)]\n",
    "    )  # [batch_size * num_target_boxes]\n",
    "    src_idx = torch.cat(\n",
    "        [src for (src, _) in indices]\n",
    "    )  # [batch_size * num_target_boxes]\n",
    "    return batch_idx, torch.div(src_idx, num_references, rounding_mode='floor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_refsize = [1, 2, 4, 8]\n",
    "\n",
    "def boxes_to_labels(boxes):\n",
    "    # area_range = [[0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
    "    # area_label = [\"small\", \"medium\", \"large\"]\n",
    "    assert (boxes[..., 2:] >= boxes[..., :2]).all().item()\n",
    "    areas = torch.prod(boxes[..., 2:] - boxes[..., :2], dim=-1)\n",
    "    labels = []\n",
    "\n",
    "    for area in areas:\n",
    "        area = area.item()\n",
    "\n",
    "        if area < (32 ** 2):\n",
    "            labels.append(0) # small\n",
    "        elif area < (96 ** 2):\n",
    "            labels.append(1) # medium\n",
    "        else:\n",
    "            labels.append(2) # large\n",
    "\n",
    "    return torch.tensor(labels, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimPLRDemo:\n",
    "    def __init__(self, root_path, model_path, config_path, current_device=torch.device(\"cuda\")):\n",
    "        model_path = os.path.join(root_path, model_path)\n",
    "        config_path = os.path.join(root_path, config_path)\n",
    "        self.current_device = current_device\n",
    "        print(\"Loading model from\", model_path)\n",
    "        \n",
    "        self.config = load_yaml(config_path)\n",
    "        self._init_processors()\n",
    "\n",
    "        self.model = self._build_simplr(model_path)\n",
    "        self.matcher = build_matcher(self.config.loss.params.matcher)\n",
    "\n",
    "    def _init_processors(self):\n",
    "        task = self.config.task\n",
    "        task_config = getattr(self.config.dataset_config, task)\n",
    "        \n",
    "        self.prepare = ConvertCocoPolysToMask(task_config[\"use_mask\"])\n",
    "        self.dataset = build_dataset(self.config, \"val\", self.current_device)\n",
    "\n",
    "    def _build_simplr(self, model_path):\n",
    "        num_classes = self.dataset.get_answer_size()\n",
    "        other_args = {\"num_classes\": num_classes}\n",
    "        \n",
    "        model = build_model(self.config, **other_args)\n",
    "        \n",
    "        ext = model_path.split(\".\")[-1]\n",
    "        state_dict = torch.load(model_path, map_location=\"cpu\")\n",
    "        if ext == \"ckpt\":\n",
    "            state_dict = state_dict[\"model\"]\n",
    "            \n",
    "        if list(state_dict.keys())[0].startswith('module') and not hasattr(model, 'module'):\n",
    "            state_dict = self._multi_gpu_state_to_single(state_dict)\n",
    "        \n",
    "        print(\"Loading model:\", model.load_state_dict(state_dict))\n",
    "        model.to(self.current_device)\n",
    "        model.eval()\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def _multi_gpu_state_to_single(self, state_dict):\n",
    "        new_sd = {}\n",
    "        for k, v in state_dict.items():\n",
    "            if not k.startswith('module.'):\n",
    "                raise TypeError(\"Not a multiple GPU state of dict\")\n",
    "            k1 = k[7:]\n",
    "            new_sd[k1] = v\n",
    "        return new_sd\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, idx=0):\n",
    "        sample, target = self.dataset[idx]\n",
    "        \n",
    "        batch = collate2d([(sample, target)])\n",
    "\n",
    "        sample, target = self.dataset.prepare_batch(batch)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            outputs = self.model(sample, target)\n",
    "\n",
    "        enc_output = outputs[\"enc_outputs\"][0]\n",
    "        \n",
    "        bin_target = copy.deepcopy(target)\n",
    "        for bt in bin_target:\n",
    "            bt[\"labels\"] = torch.zeros_like(bt[\"labels\"])\n",
    "\n",
    "        indices = self.matcher(enc_output, bin_target)\n",
    "\n",
    "        attn = self.model.transformer.encoder.layers[5].self_attn.attn.float()\n",
    "        boxes = self.model.transformer.encoder.layers[5].self_attn.boxes.float()\n",
    "        vit_attn = self.model.backbone.net.blocks[11].attn.attn.float()\n",
    "\n",
    "        src_idx = _get_src_permutation_idx(indices)\n",
    "        boxes_target = torch.cat([t[\"boxes\"][i] for t, (_, i) in zip(target, indices)], dim=0)\n",
    "        size = target[0][\"orig_size\"]\n",
    "\n",
    "        boxes_target = box_cxcywh_to_xyxy(boxes_target * size[[1, 0, 1, 0]])\n",
    "        labels = boxes_to_labels(boxes_target)\n",
    "        attn = attn[src_idx]\n",
    "        boxes = box_cxcywh_to_xyxy(boxes[src_idx] * size[[1, 0, 1, 0]])\n",
    "\n",
    "        return attn, boxes, labels, vit_attn, src_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /media/deepstorage01/home2/duykien/test/3D-ObjectDect/e2edet/../save/COCO-InstanceSegmentation/boxer2d_vit/boxer2d_vit_b_w16_4g_5x_ss_lsj_final/boxer2d_vit_final.pth\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "loss_mode: focal\n",
      "Loaded pretrained mae_base_patch16: _IncompatibleKeys(missing_keys=['blocks.0.attn.rel_pos_h', 'blocks.0.attn.rel_pos_w', 'blocks.1.attn.rel_pos_h', 'blocks.1.attn.rel_pos_w', 'blocks.2.attn.rel_pos_h', 'blocks.2.attn.rel_pos_w', 'blocks.3.attn.rel_pos_h', 'blocks.3.attn.rel_pos_w', 'blocks.4.attn.rel_pos_h', 'blocks.4.attn.rel_pos_w', 'blocks.5.attn.rel_pos_h', 'blocks.5.attn.rel_pos_w', 'blocks.6.attn.rel_pos_h', 'blocks.6.attn.rel_pos_w', 'blocks.7.attn.rel_pos_h', 'blocks.7.attn.rel_pos_w', 'blocks.8.attn.rel_pos_h', 'blocks.8.attn.rel_pos_w', 'blocks.9.attn.rel_pos_h', 'blocks.9.attn.rel_pos_w', 'blocks.10.attn.rel_pos_h', 'blocks.10.attn.rel_pos_w', 'blocks.11.attn.rel_pos_h', 'blocks.11.attn.rel_pos_w'], unexpected_keys=['cls_token'])\n",
      "resize {'s1': 384} {'s1': 8} {'s1': {'channels': 768, 'stride': 16}}\n",
      "Loading model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "demo = SimPLRDemo(log_dir, model_path, config_path, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 12, 4, 4])\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "attn, boxes, labels, vit_attn, src_idx = demo.predict(idx)\n",
    "print(attn.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 1, 1, 1, 0, 0, 1])\n",
      "torch.Size([1, 12, 4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(vit_attn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16431/1817803128.py:14: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  h_idx, w_idx = (len_idx // 128) // 2, (len_idx % 128) // 2\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "ids = list(torch.load(\"ids.pth\"))\n",
    "\n",
    "y, x = torch.meshgrid((torch.arange(64) + 0.5), (torch.arange(64) + 0.5), indexing=\"ij\")\n",
    "coords = torch.stack([x, y], dim=-1).flatten(0, 1).float()\n",
    "\n",
    "rel_dist = torch.cdist(coords.unsqueeze(0), coords.unsqueeze(0)).cuda()\n",
    "\n",
    "for idx in ids:\n",
    "    attn, boxes, labels, vit_attn, src_idx = demo.predict(idx)\n",
    "\n",
    "    batch_idx, len_idx = src_idx\n",
    "    h_idx, w_idx = (len_idx // 128) // 2, (len_idx % 128) // 2\n",
    "    len_idx = h_idx * 64 + w_idx\n",
    "    vit_attn = (vit_attn[:, :, len_idx] * rel_dist[:, len_idx].unsqueeze(0)).sum(-1).squeeze(0).transpose(0, 1)\n",
    "\n",
    "    stats[idx] = (attn.cpu(), boxes.cpu(), labels, vit_attn.cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(stats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = torch.cat([stats[idx][0][stats[idx][2] == 2] for idx in ids], dim=0)\n",
    "medium = torch.cat([stats[idx][0][stats[idx][2] == 1] for idx in ids], dim=0)\n",
    "small = torch.cat([stats[idx][0][stats[idx][2] == 0] for idx in ids], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n",
      "217\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "print(large.shape[0])\n",
    "print(medium.shape[0])\n",
    "print(small.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large: Counter({3: 965, 1: 651, 0: 570, 2: 562})\n",
      "medium: Counter({0: 865, 1: 842, 2: 827, 3: 70})\n",
      "small: Counter({0: 1375, 1: 884, 3: 84, 2: 81})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "large_stats = Counter(large.sum(-1).max(dim=-1)[1].flatten().tolist())\n",
    "print(\"large:\", large_stats)\n",
    "\n",
    "medium_stats = Counter(medium.sum(-1).max(dim=-1)[1].flatten().tolist())\n",
    "print(\"medium:\", medium_stats)\n",
    "\n",
    "small_stats = Counter(small.sum(-1).max(dim=-1)[1].flatten().tolist())\n",
    "print(\"small:\", small_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_large = torch.cat([stats[idx][3][stats[idx][2] == 2] for idx in ids], dim=0)\n",
    "vit_medium = torch.cat([stats[idx][3][stats[idx][2] == 1] for idx in ids], dim=0)\n",
    "vit_small = torch.cat([stats[idx][3][stats[idx][2] == 0] for idx in ids], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_large: tensor(253.3443) tensor(6.1593)\n",
      "vit_medium: tensor(209.3601) tensor(7.1412)\n",
      "vit_small: tensor(201.6862) tensor(6.8789)\n"
     ]
    }
   ],
   "source": [
    "print(\"vit_large:\", vit_large.mean() * 16, vit_large.std(-1).mean())\n",
    "print(\"vit_medium:\", vit_medium.mean() * 16, vit_medium.std(-1).mean())\n",
    "print(\"vit_small:\", vit_small.mean() * 16, vit_small.std(-1).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
