\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{bao2022beit}
Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In {\em ICLR}, 2022.

\bibitem{brown2020gpt3}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Sandhini~Agarwal Amanda~Askell, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{cai2019cascadercnn}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade r-cnn: High quality object detection and instance segmentation.
\newblock {\em TPAMI}, 2019.

\bibitem{nicolas2020detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{chen2020igpt}
Mark Chen, Alec Radford, Rewon Child, Jeff Wu, Heewoo Jun, Prafulla Dhariwal, David Luan, and Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{chen2020simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In {\em ICML}, 2020.

\bibitem{chen2022uvit}
Wuyang Chen, Xianzhi Du, Fan Yang, Lucas Beyer, Xiaohua Zhai, Tsung-Yi Lin, Huizhong Chen, Jing Li, Xiaodan Song, Zhangyang Wang, and Denny Zhou.
\newblock A simple single-scale vision transformer for object localization and instance segmentation.
\newblock In {\em ECCV}, 2022.

\bibitem{cheng2022mask2former}
Bowen Cheng, Ishan Misra, Alexander~G. Schwing, Alexander Kirillov, and Rohit Girdhar.
\newblock Mask2former: Masked-attention mask transformer for universal image segmentation.
\newblock In {\em CVPR}, 2022.

\bibitem{cheng2021maskformer}
Bowen Cheng, Alexander~G. Schwing, and Alexander Kirillov.
\newblock Per-pixel classification is not all you need for semantic segmentation.
\newblock In {\em NeurIPS}, 2021.

\bibitem{dehghani2022scalingvit22b}
Mostafa Dehghani, Josip Djolonga, Basil Mustafa, Piotr Padlewski, Jonathan Heek, Justin Gilmer, Andreas Steiner, Mathilde Caron, Robert Geirhos, Ibrahim Alabdulmohsin, Rodolphe Jenatton, Lucas Beyer, Michael Tschannen, Anurag Arnab, Xiao Wang, Carlos Riquelme, Matthias Minderer, Joan Puigcerver, Utku Evci, Manoj Kumar, Sjoerd van Steenkiste, Gamaleldin~F. Elsayed, Aravindh Mahendran, Fisher Yu, Avital Oliver, Fantine Huot, Jasmijn Bastings, Alexey~Gritsenko Mark Patrick~Collier, Vighnesh Birodkar, Cristina Vasconcelos, Yi Tay, Thomas Mensink, Alexander Kolesnikov, Filip Pavetić, Dustin Tran, Thomas Kipf, Mario Lučić, Xiaohua Zhai, Daniel Keysers, Jeremiah Harmsen, and Neil Houlsby.
\newblock Scaling vision transformers to 22 billion parameters.
\newblock {\em arXiv preprint arXiv:2302.05442}, 2023.

\bibitem{deng2009imagenet}
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock In {\em ACL}, 2019.

\bibitem{dong2021solq}
Bin Dong, Fangao Zeng, Tiancai Wang, Xiangyu Zhang, and Yichen Wei.
\newblock {SOLQ}: Segmenting objects by learning queries.
\newblock In {\em NeurIPS}, 2021.

\bibitem{dosovitskiy2021vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em ICLR}, 2021.

\bibitem{fan2021mvit}
Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra Malik, and Christoph Feichtenhofer.
\newblock Multiscale vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{shiasi2021lsjitter}
Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, TsungYi Lin, Ekin~D Cubuk, Quoc~V Le, and Barret Zoph.
\newblock Simple copy-paste is a strong data augmentation method for instance segmentation.
\newblock In {\em CVPR}, 2021.

\bibitem{girshick2014rcnn}
Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik.
\newblock Rich feature hierarchies for accurate object detection and semantic segmentation.
\newblock In {\em CVPR}, 2014.

\bibitem{he2022mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em CVPR}, 2022.

\bibitem{he2017maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
\newblock Mask {R-CNN}.
\newblock In {\em ICCV}, 2017.

\bibitem{kaiming2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{heo2021rethinkingvit}
Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe, and Seong~Joon Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{huang2017densenet}
Gao Huang, Zhuang Liu, Laurens van~der Maaten, and Kilian~Q. Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em CVPR}, 2017.

\bibitem{lecun95convolutional}
Yann LeCun and Yoshua Bengio.
\newblock {\em Convolutional Networks for Images, Speech and Time Series}, pages 255--258.
\newblock MIT Press, 1995.

\bibitem{li2022vitdet}
Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock In {\em ECCV}, 2022.

\bibitem{lin2014mscoco}
Tsung{-}Yi Lin, Michael Maire, Serge~J. Belongie, Lubomir~D. Bourdev, Ross~B. Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'{a}}r, and C.~Lawrence Zitnick.
\newblock Microsoft {COCO:} common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{tsung2017fpn}
Tsung-Yi {Lin}, Piotr {Dollár}, Ross {Girshick}, Kaiming {He}, Bharath {Hariharan}, and Serge {Belongie}.
\newblock Feature pyramid networks for object detection.
\newblock In {\em CVPR}, 2017.

\bibitem{wei2016ssd}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander~C. Berg.
\newblock Ssd: Single shot multibox detector.
\newblock In {\em ECCV}, 2016.

\bibitem{liu2021swintransformer}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In {\em ICCV}, 2021.

\bibitem{loshchilov2019adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2019.

\bibitem{nguyen2022boxer}
Duy{-}Kien Nguyen, Jihong Ju, Olaf Booij, Martin~R. Oswald, and Cees G.~M. Snoek.
\newblock Boxer: Box-attention for 2d and 3d transformers.
\newblock In {\em CVPR}, 2022.

\bibitem{pinheiro2016refineobject}
Pedro H.~O. Pinheiro, Tsung{-}Yi Lin, Ronan Collobert, and Piotr Doll{\'{a}}r.
\newblock Learning to refine object segments.
\newblock In {\em ECCV}, 2016.

\bibitem{ren2015faster_rcnn}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster {R-CNN}: Towards real-time object detection with region proposal networks.
\newblock In {\em NeurIPS}, 2015.

\bibitem{sermanet2014overfeat}
Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, and Yann LeCun.
\newblock Overfeat: Integrated recognition, localization and detection using convolutional networks.
\newblock In {\em ICLR}, 2014.

\bibitem{simonyan2015vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{uijlings2013selective}
Jasper~R.R. Uijlings, Koen~E.A. van~de Sande, Theo Gevers, and Arnold~W.M. Smeulders.
\newblock Selective search for object recognition.
\newblock {\em IJCV}, 2013.

\bibitem{vaswani2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2021pvit}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction without convolutions.
\newblock In {\em ICCV}, 2021.

\bibitem{xie2017resnext}
Saining Xie, Ross~B. Girshick, Piotr Doll{\'{a}}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em CVPR}, 2017.

\bibitem{yu2022kmmask}
Qihang Yu, Huiyu Wang, Siyuan Qiao, Maxwell Collins, Yukun Zhu, Hartwig Adam, Alan Yuille, and Liang-Chieh Chen.
\newblock k-means mask transformer.
\newblock In {\em ECCV}, 2022.

\bibitem{zhai2022scalingvit}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In {\em CVPR}, 2022.

\bibitem{zhang2021knet}
Wenwei Zhang, Jiangmiao Pang, Kai Chen, and Chen~Change Loy.
\newblock K-net: Towards unified image segmentation.
\newblock In {\em NeurIPS}, 2021.

\bibitem{zhu2021deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable {DETR}: Deformable transformers for end-to-end object detection.
\newblock In {\em ICLR}, 2021.

\end{thebibliography}
